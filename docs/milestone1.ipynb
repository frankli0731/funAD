{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-L2Ye37HpeDl",
        "outputId": "4fdaa0e5-2289-42f9-b365-1ee57509f7f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "blockquote { background: #AEDE94; }\n",
              "h1 { \n",
              "    padding-top: 25px;\n",
              "    padding-bottom: 25px;\n",
              "    text-align: left; \n",
              "    padding-left: 10px;\n",
              "    background-color: #DDDDDD; \n",
              "    color: black;\n",
              "}\n",
              "h2 { \n",
              "    padding-top: 10px;\n",
              "    padding-bottom: 10px;\n",
              "    text-align: left; \n",
              "    padding-left: 5px;\n",
              "    background-color: #EEEEEE; \n",
              "    color: black;\n",
              "}\n",
              "\n",
              "div.exercise {\n",
              "\tbackground-color: #ffcccc;\n",
              "\tborder-color: #E9967A; \t\n",
              "\tborder-left: 5px solid #800080; \n",
              "\tpadding: 0.5em;\n",
              "}\n",
              "\n",
              "div.exercise-r {\n",
              "\tbackground-color: #fce8e8;\n",
              "\tborder-color: #E9967A; \t\n",
              "\tborder-left: 5px solid #800080; \n",
              "\tpadding: 0.5em;\n",
              "}\n",
              "\n",
              "\n",
              "span.sub-q {\n",
              "\tfont-weight: bold;\n",
              "}\n",
              "div.theme {\n",
              "\tbackground-color: #DDDDDD;\n",
              "\tborder-color: #E9967A; \t\n",
              "\tborder-left: 5px solid #800080; \n",
              "\tpadding: 0.5em;\n",
              "\tfont-size: 18pt;\n",
              "}\n",
              "div.gc { \n",
              "\tbackground-color: #AEDE94;\n",
              "\tborder-color: #E9967A; \t \n",
              "\tborder-left: 5px solid #800080; \n",
              "\tpadding: 0.5em;\n",
              "\tfont-size: 12pt;\n",
              "}\n",
              "p.q1 { \n",
              "    padding-top: 5px;\n",
              "    padding-bottom: 5px;\n",
              "    text-align: left; \n",
              "    padding-left: 5px;\n",
              "    background-color: #EEEEEE; \n",
              "    color: black;\n",
              "}\n",
              "header {\n",
              "   padding-top: 35px;\n",
              "    padding-bottom: 35px;\n",
              "    text-align: left; \n",
              "    padding-left: 10px;\n",
              "    background-color: #DDDDDD; \n",
              "    color: black;\n",
              "}\n",
              "</style>\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# RUN THIS CELL FOR FORMAT\n",
        "import requests\n",
        "from IPython.core.display import HTML\n",
        "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
        "HTML(styles)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"contents\"></a>\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "- [**1. Introduction**](#introduction)\n",
        "\n",
        "> - [**1.1 Derivatives and Differentiation Methods**](#introduction1)\n",
        "> - [**1.2 Differentiation Methods and Motivations**](#introduction2)\n",
        "> - [**1.3 Automatic Differentiation**](#introduction3)\n",
        "\n",
        "- [**2. Background**](#background)\n",
        "\n",
        "> - [**2.1 Chain Rule**](#background1)\n",
        "\n",
        "> - [**2.2 Elementary Functions**](#background2)\n",
        "\n",
        "> - [**2.3 Forward Mode**](#background3)\n",
        "\n",
        "> - [**2.4 Reverse Mode**](#background4)\n",
        "\n",
        "> - [**2.5 Dual Number**](#background5)\n",
        "\n",
        "- [**3. Usage**](#usage)\n",
        "\n",
        "> - [**3.1 Installation**](#usage1)\n",
        "\n",
        "> - [**3.2 How to use**](#usage2)\n",
        "\n",
        "- [**4. Software Organization**](#softwareorganization)\n",
        "\n",
        "- [**5. Implementation**](#implementation)\n",
        "\n",
        "- [**6. Reference**](#reference)\n"
      ],
      "metadata": {
        "id": "lzCEzrwWqYFK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"introduction\"></a>\n",
        "\n",
        "## Introduction\n",
        "\n",
        "[Return to contents](#contents)"
      ],
      "metadata": {
        "id": "u3GKCq4UqyNE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[package name], [package description], is a PyPi-distributed package that executes forward-mode and reverse-mode of automatic differentiation, enabling users to solve functional derivatives with high computational efficiency and machine precision."
      ],
      "metadata": {
        "id": "tXKNjfecyeGz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"introduction1\"></a>\n",
        "\n",
        "###1.1 Derivatives\n",
        "\n",
        "[Return to contents](#contents)"
      ],
      "metadata": {
        "id": "-nichMJUsBmp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The derivative measures the sensitivity of the function value with respect to changes in its arguments. In one dimensional space, let $I \\subseteq \\mathbb{R}$ be an interval and let $x_0 \\in I$. If exists, the derivative of the real-valued, single variable function $f \\colon I → \\mathbb{R}$ at $x_0$ is defined as,\n",
        "\n",
        "$$f'(x_0) =\\lim_{h→0} \\frac{f(x_0+h)-f(x_0)}{h}$$\n",
        "\n",
        "In multiple dimensions, for a vector-valued function of several variables, such as the mapping $f \\colon \\mathbb{R}^{m} → \\mathbb{R}^{n}$, the partial derivative of the $i$th vector component of function output with respect to the $j$th input can be written as,\n",
        "\n",
        "$$\\frac{\\partial}{\\partial{x_j}}f_i(\\textbf{x}) = \\lim_{h→0}\\frac{f_i(x_1, x_2, ..., x_{j-1}, x_{j}+h, x_{j+1},...,x_{m})-f_i(x_1, x_2, ..., x_{j-1}, x_{j}, x_{j+1},...,x_{m})}{h}$$\n",
        "\n",
        "\n",
        "In this case, the Jacobian matrix consisting of all the first-order partial derivatives of the function is often considered. The Jacobian $J(\\textbf{x}^{(k)})$ of $f(\\textbf{x})$ evaluated at $\\textbf{x}^{(k)}$ will be a $n \\times m$ matrix with elements \n",
        "\n",
        "$$J(\\textbf{x}^{(k)})_{i,j} = \\frac{\\partial{f_i}}{\\partial{x_j}}\\Bigr\\rvert_{\\textbf{x} = {x}^{(k)}}$$"
      ],
      "metadata": {
        "id": "vrCoiS8Syjju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"introduction2\"></a>\n",
        "\n",
        "###1.2 Differentiation Methods and Motivations\n",
        "\n",
        "[Return to contents](#contents)\n"
      ],
      "metadata": {
        "id": "4x7GHQ46-uY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Differentiation is one of the most fundamental operations in science with a wide range of applications, including optimization, linearization, and root-finding problems. Several approaches to carry out the task have been proposed and gained great ubiquity:\n",
        " * Symbolic calculus methods accept an expression of a function and return the derivative of the given formula with respect to a specified variable. Despite offering analytical solutions at one's disposal, which has benefits in and of itself, symbolic mathematics programs usually have a high computation cost and may not always be applicable especially in cases of discontinuity, high complexity, and non-smoothness while finding the exact form of the derivative as a function. \n",
        " * Numerical differentiation, such as the three-point forward difference formula, employs finite differences approximation to find rate of change of function value at a given point in the domain. Due to the nature of the approximation, it suffers from inaccuracy and instability.\n",
        " * In comparison, the automatic differentiation algorithm has the advantage of attaining both low computational costs and machine precision, overcoming the deficiencies of the two other methods introduced above. Its superior performance lies in its intricate design and implementation, which we will cover in the next section."
      ],
      "metadata": {
        "id": "op02rpn0-4iO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"introduction3\"></a>\n",
        "\n",
        "###1.3 Automatic Differentiation\n",
        "\n",
        "[Return to contents](#contents)"
      ],
      "metadata": {
        "id": "URR4xYv1rGPX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As mentioned above, Automatic Differentiation is a compotent tool for computing the Jacobian with reasonable computational costs and optimal accurcay, and thus making great contribution to progress made in fluid dynamics, aerospace, and so on. For instance, the back-propagation algorithm, a special case of reverse mode AD applied to scaler functions, is utilized to update node weights of neural network in machine learning. Here, [package name] provides a robust, readily accessible implementation of the algorithm."
      ],
      "metadata": {
        "id": "bC12F6KEym2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"background\"></a>\n",
        "\n",
        "##2. background\n",
        "AD calculates derivatives with the same accuracy as symbolic differentiation, but operates directly on the program of interest to obtain numerical values. The fundamental principle of AD is to decompose complex functions into elementary functions with known derivatives that form evaluation traces, and apply the chain rule to compose the derivatives of each step. Hence we first introduce chain rule and elementary function in order to understand AD.\n",
        "\n",
        "[Return to contents](#contents)"
      ],
      "metadata": {
        "id": "nUYZ8abwtQwi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"background1\"></a>\n",
        "\n",
        "###2.1 Chain Rule\n",
        "\n",
        "\n",
        "\n",
        "[Return to contents](#contents)"
      ],
      "metadata": {
        "id": "VmXMLW_Jtq2L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The central idea of Automatic Differentiation is the decomposition of complicated functional relations and the piecewise determination of derivatives based on the generalized Chain Rule.  \n",
        "\n",
        "To recall, according to the Chain Rule, for scalar-valued function of one real variable $f(x)$ and $g(x)$,\n",
        "\n",
        "$$\\frac{\\text{d}}{\\text{d}x} (f(g(x))) = f'(g(x))g'(x)$$\n",
        "\n",
        "When extended to real-valued functions of multiple variables in high dimensional coordinates $f\\colon \\mathbb{R}^n → \\mathbb{R}$, the Chain Rule states that,\n",
        "\n",
        "$$\\nabla_{\\textbf{x}} f = \\sum_{i=1}^{n} \\frac{\\partial{f}}{\\partial{y_i}} \\nabla y_i(\\textbf{x})$$\n",
        "\n",
        "where $\\textbf{x} = [x_1,x_2,...,x_m] \\in \\mathbb{R}^m$ vector of independent coordinates, $y(\\textbf{x}) = [y_1(\\textbf{x}), y_2(\\textbf{x}), ...,y_n(\\textbf{x})] \\in \\mathbb{R}^n$ n-dimenstional input vector of $f$, and $\\nabla y_i(\\textbf{x}) = [\\frac{\\partial{y_i}}{\\partial{x_1}}, \\frac{\\partial{y_i}}{\\partial{x_2}}, ...,\\frac{\\partial{y_i}}{\\partial{x_m}}]{ᵀ}$ \n",
        "\n",
        "\n",
        "In the most generalized form, the output of $f$ would be a vector instead of a scaler, in which case the derivative of each component $f_k$ can be following the Chain Rule. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Rc0Cgj9ejjgA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"background2\"></a>\n",
        "\n",
        "###2.2 Elementary Functions\n",
        "\n",
        "[Return to contents](#contents)"
      ],
      "metadata": {
        "id": "8vANjXOpuR6d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A complex function formula is made up of basic unitary and binary operations, a concept known as the partial ordering of the operations associated with the function $f$. Using these operations as delimiters, a function can be broken down into a handful parallel and enclosing elementary functions. \n",
        "\n",
        "Specifically, an elementary function is a function of a single variable that is defined as taking sums, products, roots and compositions of finitely many polynomial, rational, trigonometric, hyperbolic, and exponential functions, including possibly their inverse functions.$^1$Some common examples include,\n",
        "\n",
        "* Constant functions: 2, $\\pi$,$e$\n",
        "* Rational powers of x: $x$,$x^3$,$\\sqrt{x}$\n",
        "* Exponential and logrithmic functions: $e^{x}$, $\\ln{x}$, $10^{x}$,$\\log_2{x}$\n",
        "* Trignometric functions: $\\sin(x)$\n",
        "\n",
        "With evaluate intermediate results\n",
        "intermediate steps"
      ],
      "metadata": {
        "id": "3NZDHEDLcoQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"background3\"></a>\n",
        "\n",
        "###2.3 Forward Mode\n",
        "\n",
        "Forward Mode is prefered when computing Jacobians where n is much lesser than m, i.e. the dimension of inputs significantly smaller than the dimension of outputs.\n",
        "$$ f: \\mathbb{R}^{n} → \\mathbb{R}^{m}$$\n",
        "\n",
        "In forward mode, we compute the inner product of $$\\gradient f * p$$\n",
        "where $\\gradient f$ refers to the Jacobian and p refers to the seed vector.\n",
        "####2.3.1 Jacobian\n",
        "####2.3.2 Seed Vector\n",
        "\n",
        "Here is an exmaple\n",
        "\n",
        "add computational graph, trace table\n",
        "[Return to contents](#contents)"
      ],
      "metadata": {
        "id": "U_y-ySLCtxt2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Gj4ikk24cZvx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uGxtERRrcaeY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"background4\"></a>\n",
        "\n",
        "###2.4 Reverse Mode\n",
        "\n",
        "The reverse mode is ideal when the dimensionality of the input is significantly larger than the dimensionality of the output. Instead of propagating the derivative forward as the forward mode does, the reverse mode propagates the derivative backward from the output. The reverse mode consists of two parts: forward pass and reverse pass. \n",
        "During the forward pass, we evaluate the intermediate variables $v_{i}$, \n",
        "\n",
        "####2.4.1 Forward Pass\n",
        "During the forward pass, we evaluate the intermediate variables $v_{i}$ and store the partial derivatives of child nodes with respect to their parent node in memory$$\\frac{\\partial{v_{j}}}{\\partial{v_{i}}}$$\n",
        "\n",
        "####2.4.2 Reverse Pass\n",
        "In reverse mode, we compute the paritial derivates of the output with respect to the intermediate variables known as adjoints iteratively. The adjoint is denoted as $v_{i}$, where\n",
        "$$ \\bar{v_{i}} = \\frac{\\partial{f}}{\\partial{v_{i}}} = \\sum_{j: child of i} \\frac{\\partial{f}}{\\partial{v_{j}}}\\frac{\\partial{v_{j}}}{\\partial{v_{i}}}$$\n",
        "\n",
        "For each specific node, we first apply chain rule to multiple the adjoint of child by the partial derivate of the child with respect to $v_{i}$ and take the sum of these products. In other words, $v_{i}$'s contribution to the output is defined by its children's contribution to the output as well as its affect on children. In this case, we obtain partial derivate of each input. \n",
        "\n",
        "####2.4.3 Comparison to Forward Mode\n",
        "In contrast to the forward mode, the reverse mode of AD does not involve directional derivatives. Instead, it calculates and stores the partial derivatives. The reverse mode can only run after the forward pass is completed and it is memeory-intensive\n",
        "\n",
        "[Return to contents](#contents)"
      ],
      "metadata": {
        "id": "z94q4rtjuHjo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"background5\"></a>\n",
        "\n",
        "###2.5 Dual Number\n",
        "\n",
        "A dual number consists of a real part and a dual part, with the following format $$z=a+bϵ$$ where a represents the real part $f$, b represents the dual part $f\\prime$, and $\\epsilon$ is a nonzero and nonreal number which satisfies $\\epsilon^2=0$.\n",
        "\n",
        "Noticing the format of dual numbers is very similar to complex numbers. The key difference here is that for dual numbers $\\epsilon^2=0$ whereas for complex number $i^2=-1$.\n",
        "\n",
        "Dual numbers are extremely useful when calculating function values and function derivatives in AD setups. For instance, say we have $$f(x) = x^2$$ and would like to calculate $f(x)$ and $f\\prime(x)$. We first convert x into a dual number as $x=a+bϵ$. Then $$f(x) = (a+bϵ)^2 = a^2 + 2abϵ + b^2ϵ^2 = a^2 + abϵ $$ where $f(x) = a^2$ and $f\\prime(x) = 2abϵ$. \n",
        "\n",
        "[Return to contents](#contents)"
      ],
      "metadata": {
        "id": "lzl8Yds3umJI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"usage\"></a>\n",
        "\n",
        "##3. Usage\n",
        "\n",
        "[Return to contents](#contents)\n",
        "\n",
        "[package name] is available through the Python Package Index (PyPI). Refer to the PyPI webpage for more project description."
      ],
      "metadata": {
        "id": "d6DkHWwqwRzH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"usage1\"></a>\n",
        "\n",
        "###3.1 Installation\n",
        "\n",
        "[Return to contents](#contents)\n",
        "\n",
        "To install [package name] with pip, run the following command:\n",
        "\n",
        "    pip install [package name]"
      ],
      "metadata": {
        "id": "PJOwqEuCwWxH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"usage2\"></a>\n",
        "\n",
        "###3.2 How to use\n",
        "\n",
        "[Return to contents](#contents)\n",
        "\n",
        "Aftering successful installation, the user can import [package name] and perform AD computation.\n",
        "\n",
        "The package provides the following APIs:\n",
        "\n",
        "\n",
        "*   Instanitiate AD objects, with forward/reverse mode specified\n",
        "*   Compute the value of the function\n",
        "*   Compute the gradient/Jacobian of the function\n",
        "*   Compute the directional derivative of the function with seed vector p specified\n",
        "\n",
        "The sample code illustrates how to use the package."
      ],
      "metadata": {
        "id": "PgJYYCbBwaWm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"softwareorganization\"></a>\n",
        "\n",
        "##4. Software Organization\n",
        "\n",
        "[Return to contents](#contents)"
      ],
      "metadata": {
        "id": "dD-IfQe_wf_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Directory Structure\n",
        "\n",
        "```\n",
        "├── __init__.py\n",
        "├── Docs\n",
        "│   ├── README.md\n",
        "│   ├── milestone1.md\n",
        "│   │   ...\n",
        "└───AD4fun\n",
        "│   ├── README.md\n",
        "│   ├── forward_mode_class.py\n",
        "│   ├── reverse_mode_class.py\n",
        "│   ├── elementary_functions.py\n",
        "│   ├── dual_number_class.py\n",
        "│   ├── core_data_classes.py\n",
        "│   │   ...\n",
        "│\n",
        "└───Test toolbox\n",
        "│   ├── README.md\n",
        "│   ├── core_data_initialization_test.py\n",
        "│   ├── forward_mode_test.py\n",
        "│   ├── reverse_mode_test.py\n",
        "│   ├── elementary_function_test.py\n",
        "│   ├── class_dual_number_test.py\n",
        "│   ├── formula_conversion_test.py\n",
        "│   │   ...\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "SUWHEoLg-OLP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Packaging & Distribution**\n",
        "\n",
        "We build and package our software using the the standard packaging tool. [setuptools](https://packaging.python.org/key_projects/#setuptools)\n",
        "\n",
        "Our code follows PEP8 standard.\n",
        "\n",
        "Our package would be distributed through [Python Package Index (PyPi)](https://pypi.org/)\n",
        "\n",
        "<br>\n",
        "\n",
        "**Modules to Include**\n",
        "\n",
        " math: performing elementary functions and mathematic algebric operations\n",
        "\n",
        " numpy: provide multi-dimensional array and matrix computation support\n",
        "\n",
        "<br>\n",
        "\n",
        " **Test Toolbox Design**\n",
        "\n",
        "The functionality tests will be included in the test toolbox directory in the root directory. We plan to use TravisCI to test coverage and integration.\n"
      ],
      "metadata": {
        "id": "3YVnP7716VXM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"implementation\"></a>\n",
        "\n",
        "##5. Implementation\n",
        "\n",
        "[Return to contents](#contents)"
      ],
      "metadata": {
        "id": "_Eyw_0H0wnnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Classes"
      ],
      "metadata": {
        "id": "05sW8oblfbTG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####5.1 Core Data structures\n",
        "\n",
        "As per our current design, we plan to use the following core data structures - all computations and functions would be implemented around those central classes\n",
        "\n",
        "1. `Formula` objects\n",
        "\n",
        "This class will have many subclasses each handling one kind of mathematical expressions such as sine, cosine, natural logrithm etc. This class provides analytical differentiation and numeric evaluation interfaces which would be implemented in each subclass. Any mathematical expression would be converted into `Formula` objects. For instance, f = sin(x)**2 would be a power formula object within which contains a sine formula object - that sine object in turn contains a variable formula object.\n",
        "\n",
        "\n",
        "2. `Variable` objects\n",
        "\n",
        "`Variable` class is a special child class of formula class that represents the independent variables of a mathematical functions. For instance x,y,z  in f(x,y,z) = x + y + z\n",
        "These objects are against which mathematical functions are differentiated. \n",
        "\n",
        "3. `Variable-to-Value map` dictionary\n",
        "\n",
        "We use a python dictionary to store the hash map from each variable to its user assigned values. For instance {x:3} stores the information that x=3"
      ],
      "metadata": {
        "id": "6TGdd1dBO7dM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####5.2 Implemented Classes\n",
        "\n",
        "* Forward mode: This class will take in a list of `Formula` objects, call each Formula's own differention method, plug in differentiation result with user defined dual values for each gradient result to obtain dual number result for each function and return a list of results.\n",
        "\n",
        "* Reverse mode: This class will compute derivatives for each input `Formula` object through reverse mode and return a list of results.\n",
        "\n",
        "* Elementary function: This series of classes will overload any elementary functions such as addition, subtraction, multiplication, sine function etc. such that any computation involving a Formula object would be converted into a Formula, too. For instance f=3+x would result in f becoming a `Addition Formula`object\n",
        "\n",
        "* Dual Number Class: This class will convert any real number input and return it as a dual number,\n",
        "this saves computational power in the final plug-in-value phase of evaluating differentiation result"
      ],
      "metadata": {
        "id": "LNdW2L3NIejo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(2) Reverse mode\n",
        "\n",
        "The trace function will also be able to calculate derivatives in reverse mode by specifying the mode parameters. Take the example below as a demo"
      ],
      "metadata": {
        "id": "MSCCBPUup9LT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The table below shows some examples of elementary functions and their respective derivatives:"
      ],
      "metadata": {
        "id": "oz5X-y_4vabS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Elementary Function    | Derivative              |\n",
        "| :--------------------: | :----------------------:|\n",
        "| $x^3$                  | $3 x^{2}$               | \n",
        "| $e^x$                  | $e^x$                   |\n",
        "| $\\sin(x)$              | $\\cos(x)$               |\n",
        "| $\\ln(x)$               | $\\frac{1}{x}$           |"
      ],
      "metadata": {
        "id": "KH1ZcnUWvkfv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"reference\"></a>\n",
        "\n",
        "##6. Reference\n",
        "\n",
        "[Return to contents](#contents)"
      ],
      "metadata": {
        "id": "21IRVQJ7wtp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vaILektMwgC-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uk3uF6znwgHR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4QarzPz2wR5B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "huAsqZKDwR9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_aYPEQ09wSBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# user defined function\n",
        "f = lambda x: x - np.exp(-2.0 * np.sin(4.0 * x) * np.sin(4.0 * x))\n",
        "\n",
        "# call the trace function in undefined, and provide input x = 2\n",
        "nd.trace(f, x = 2, mode = 'reverse')\n",
        "\n",
        "# the function will return the 1st derivative when x=2.\n",
        ">>> taking derivative...\n",
        ">>> 0.674811\n"
      ],
      "metadata": {
        "id": "5Ppt4NAVpjf9",
        "outputId": "c9c35dd2-b5b8-48df-ab5e-38f0c5c6d32a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-b62f00ca8c7d>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    >>> taking derivative...\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hGzJQ4QYwSE4"
      }
    }
  ]
}